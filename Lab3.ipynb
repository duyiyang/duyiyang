{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5564ad55",
   "metadata": {},
   "source": [
    "# DSCI 572 Lab 3: CBOW model, minibatch training and (optionally) pretrained embeddings\n",
    "\n",
    "In this lab, we'll work on a familiar task, namely, sentiment analysis. We'll build a CBOW model using pytorch. We'll also incorporate pretrained embeddings which turn out to have a substantial impact on model performance. Finally, we'll investigate the impact of minibatch training and dropout on model accuracy.\n",
    "\n",
    "**Note!** This can be a good opportunity to rehearse running code on Google Colab, where you get access to a GPU. Check this [tutorial](https://www.marktechpost.com/2021/01/09/getting-started-with-pytorch-in-google-collab-with-free-gpu/). \n",
    "\n",
    "## Software Requirements\n",
    "* Python (>=3.6)\n",
    "* PyTorch (>=1.2.0)\n",
    "* Jupyter (latest)\n",
    "* Scikit Learn (>=0.23.2)\n",
    "\n",
    "## Submission Info\n",
    "* Due date: Saturday, Jan 25 at 23:59 PST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8ece9",
   "metadata": {},
   "source": [
    "\n",
    "## Tidy Submission\n",
    "rubric={mechanics:4}\n",
    "\n",
    "To get the marks for tidy submission:\n",
    "\n",
    "* Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "* Submit a PDF version of your Jupyter notebook.\n",
    "* Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)\n",
    "\n",
    "\n",
    "## Getting started\n",
    "\n",
    "You should start by downloading the lab data from the student repo `blank_labs/Lab3/data`.\n",
    "\n",
    "Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4962cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "\n",
    "# We'll use double values in our tensors\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# Checks if GPU is available, otherwise use CPU.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "torch.backends.cudnn.deterministic=True\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda02f96",
   "metadata": {},
   "source": [
    "We'll now read data for sentiment analysis. This code is given to you. \n",
    "\n",
    "We get 500 training examples, 1000 development examples and 8476 test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc2ad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 500\n",
      "Number of development examples: 1000\n",
      "Number of test examples: 8476\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/IMDB.train.tsv\", header=None, names=[\"text\", \"sentiment\"], sep=\"\\t\")[:500]\n",
    "dev = pd.read_csv(\"data/IMDB.dev.tsv\", header=None, names=[\"text\", \"sentiment\"], sep=\"\\t\")\n",
    "test = pd.read_csv(\"data/IMDB.test.tsv\", header=None, names=[\"text\", \"sentiment\"], sep=\"\\t\")\n",
    "\n",
    "print(f\"Number of training examples: {len(train)}\")\n",
    "print(f\"Number of development examples: {len(dev)}\")\n",
    "print(f\"Number of test examples: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f57f5",
   "metadata": {},
   "source": [
    "We'll then encode sentiment labels (`positive` and `negative`) as numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44979eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train.sentiment)\n",
    "\n",
    "train_y = label_encoder.transform(train.sentiment)\n",
    "dev_y = label_encoder.transform(dev.sentiment)\n",
    "test_y = label_encoder.transform(test.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04e626",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "\n",
    "We'll start by training baseline sklearn sentiment analysis systems using [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) and [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) for feature extraction. \n",
    "\n",
    "### Assignment 1.1\n",
    "rubric={accuracy:2, quality:1}\n",
    "\n",
    "Start by fitting a `CountVectorizer` and `TfidfVectorizer` using the training set `train`. For now, you don't need to worry about setting any of the parameters for either vectorizer.\n",
    "\n",
    "You can then transform our datasets into two sets of matrices:\n",
    "\n",
    "* `train_count_X`, `dev_count_X` and `test_count_X` (using `CountVectorizer`)\n",
    "* `train_tfidf_X`, `dev_tfidf_X` and `test_tfidf_X` (using `TfidfVectorizer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e4c621-6b05-423c-b77e-50687bd6464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shapes:\n",
      "Train: (500, 12035)\n",
      "Dev: (1000, 12035)\n",
      "Test: (8476, 12035)\n",
      "\n",
      "TfidfVectorizer Shapes:\n",
      "Train: (500, 12035)\n",
      "Dev: (1000, 12035)\n",
      "Test: (8476, 12035)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words=en_stopwords)\n",
    "# Fit and transform the training data\n",
    "train_count_X = count_vect.fit_transform(train.text)\n",
    "# Transform the development and test data\n",
    "dev_count_X = count_vect.transform(dev.text)\n",
    "test_count_X = count_vect.transform(test.text)\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(stop_words=en_stopwords)\n",
    "# Fit and transform the training data\n",
    "train_tfidf_X = tfidf_vect.fit_transform(train.text)\n",
    "# Transform the development and test data\n",
    "dev_tfidf_X = tfidf_vect.transform(dev.text)\n",
    "test_tfidf_X = tfidf_vect.transform(test.text)\n",
    "\n",
    "# Now you can check the shape of these matrices\n",
    "print(\"CountVectorizer Shapes:\")\n",
    "print(\"Train:\", train_count_X.shape)\n",
    "print(\"Dev:\", dev_count_X.shape)\n",
    "print(\"Test:\", test_count_X.shape)\n",
    "\n",
    "print(\"\\nTfidfVectorizer Shapes:\")\n",
    "print(\"Train:\", train_tfidf_X.shape)\n",
    "print(\"Dev:\", dev_tfidf_X.shape)\n",
    "print(\"Test:\", test_tfidf_X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafd3da",
   "metadata": {},
   "source": [
    "## Assignment 1.2\n",
    "rubric={accuracy:1, reasoning:1}\n",
    "\n",
    "You should now fit two [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) models:\n",
    "\n",
    "* `lr_count` using your count vectorizer features\n",
    "* `lr_tfidf` using your tfidf vectorizer features\n",
    "\n",
    "Evaluate your models on the **development** data using the sklearn function [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). `lr_count` should get f-score > 75% and `lr_tfidf` > 55%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147ce033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for CountVectorizer model: 0.8349358974358975\n",
      "F1 Score for TfidfVectorizer model: 0.7855227882037533\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize and fit Logistic Regression using count vectorizer features\n",
    "lr_count = LogisticRegression()\n",
    "lr_count.fit(train_count_X, train_y)\n",
    "# Predict on development data\n",
    "dev_pred_count = lr_count.predict(dev_count_X)\n",
    "# Calculate F1 score\n",
    "f1_count = f1_score(dev_y, dev_pred_count)\n",
    "print(\"F1 Score for CountVectorizer model:\", f1_count)\n",
    "\n",
    "# Initialize and fit Logistic Regression using tfidf vectorizer features\n",
    "lr_tfidf = LogisticRegression()\n",
    "lr_tfidf.fit(train_tfidf_X, train_y)\n",
    "# Predict on development data\n",
    "dev_pred_tfidf = lr_tfidf.predict(dev_tfidf_X)\n",
    "# Calculate F1 score\n",
    "f1_tfidf = f1_score(dev_y, dev_pred_tfidf)\n",
    "print(\"F1 Score for TfidfVectorizer model:\", f1_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66420c3",
   "metadata": {},
   "source": [
    "Why do you think CountVectorizer would achieve better performance than TfidfVectorizer on this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b196d6-85c2-461d-be1e-2d3bb432903f",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "CountVectorizer simply counts word frequencies, effectively capturing the importance of key words in sentiment analysis. On the other hand, TfidfVectorizer adjusts the weight of frequent words, potentially weakening their emotional impact. Therefore, in sentiment analysis tasks, CountVectorizer tends to perform better because it directly reflects the frequency of emotional words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c046c29",
   "metadata": {},
   "source": [
    "### Assignment 1.3 Optional\n",
    "rubric={accuracy:1, reasoning:2}\n",
    "\n",
    "Both `CountVectorizer` and `TfidfVectorizer` have many parameters which affects the feature vectors. Tune these parameters to achieve the best possible development accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bfb491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (CountVectorizer): 0.8240994530796268\n",
      "Best parameters (CountVectorizer): {'clf__C': 0.1, 'vect__max_df': 0.75, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n",
      "Best score (TfidfVectorizer): 0.8243290247863108\n",
      "Best parameters (TfidfVectorizer): {'clf__C': 10, 'vect__max_df': 0.5, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english', 'vect__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with CountVectorizer and Logistic Regression\n",
    "pipeline_count = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Parameters to tune for CountVectorizer\n",
    "params_count = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    'clf__C': (0.1, 1, 10)\n",
    "}\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and Logistic Regression\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Parameters to tune for TfidfVectorizer\n",
    "params_tfidf = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    'vect__use_idf': (True, False),\n",
    "    'clf__C': (0.1, 1, 10)\n",
    "}\n",
    "\n",
    "# Grid search for CountVectorizer\n",
    "grid_search_count = GridSearchCV(pipeline_count, params_count, cv=5, scoring='f1')\n",
    "grid_search_count.fit(train.text, train_y)\n",
    "print(\"Best score (CountVectorizer):\", grid_search_count.best_score_)\n",
    "print(\"Best parameters (CountVectorizer):\", grid_search_count.best_params_)\n",
    "\n",
    "# Grid search for TfidfVectorizer\n",
    "grid_search_tfidf = GridSearchCV(pipeline_tfidf, params_tfidf, cv=5, scoring='f1')\n",
    "grid_search_tfidf.fit(train.text, train_y)\n",
    "print(\"Best score (TfidfVectorizer):\", grid_search_tfidf.best_score_)\n",
    "print(\"Best parameters (TfidfVectorizer):\", grid_search_tfidf.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea64e98",
   "metadata": {},
   "source": [
    "Explain which parameters you changed and why you think these would result in an improvement in f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de20b7-3319-4eb1-b1ce-9e9310f3db74",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "We adjusted max_df to exclude common words that might interfere with classification. The setting of ngram_range enhances the model's ability to capture context and phrases. The choice of clf__C reflects control over the model's regularization strength to optimize for overfitting or underfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43343ee1",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "\n",
    "We'll then convert our training data into pytorch tensors. We *will not* use the output of sklearn vectorizers for this assignment. Instead we will directly numericalize our `train`, `dev` and `test` datasets. \n",
    "\n",
    "### Assignment 2.1\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Start by creating a [`Counter`](https://docs.python.org/3/library/collections.html#collections.Counter) `vocabulary` which gives the count for each word type in the `train` dataset.\n",
    "\n",
    "To tokenize the sentences in `train`, you can simply split at spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231b2d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 12775\n",
      "Sample word counts: [('despite', 39), ('looking', 62), ('dated', 11), ('inki', 3), ('and', 3185), ('the', 6416), ('minah', 4), ('bird', 9), ('is', 1988), ('my', 228)]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from collections import Counter\n",
    "\n",
    "# Function to tokenize text by splitting at spaces\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Create a Counter to build the vocabulary from the tokenized training data\n",
    "vocabulary = Counter()\n",
    "\n",
    "# Loop through each text entry in the train dataset and update the Counter with tokens\n",
    "for text in train.text:\n",
    "    tokens = tokenize(text)\n",
    "    vocabulary.update(tokens)\n",
    "\n",
    "# Display the size of the vocabulary and some example counts\n",
    "print(\"Vocabulary size:\", len(vocabulary))\n",
    "print(\"Sample word counts:\", list(vocabulary.items())[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fc396",
   "metadata": {},
   "source": [
    "Assertions to test your code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ecc18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "# A test which your function should pass. Note, that simply passing the test does not \n",
    "# guarantee that your function is working fully correctly.\n",
    "assert vocabulary[\"the\"] == 6416\n",
    "assert vocabulary[\"dog\"] == 7\n",
    "print('pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a9c8a",
   "metadata": {},
   "source": [
    "Next, create a mapping `word2id` which translates every word type in `vocabulary` into a unique id number in the range `1 ... len(vocabulary)`. `word2id` should also map the symbol `PAD=\"<pad>\"` to the ID `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160d36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to ID mapping: [('despite', 1), ('looking', 2), ('dated', 3), ('inki', 4), ('and', 5), ('the', 6), ('minah', 7), ('bird', 8), ('is', 9), ('my', 10)]\n",
      "ID for PAD: 0\n"
     ]
    }
   ],
   "source": [
    "PAD = \"<pad>\"\n",
    "\n",
    "# Create a dictionary that maps each word to a unique ID, starting from 1\n",
    "word2id = {word: idx + 1 for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "# Add the PAD symbol with an ID of 0\n",
    "word2id[PAD] = 0\n",
    "\n",
    "# Display the mapping for some words\n",
    "print(\"Sample word to ID mapping:\", list(word2id.items())[:10])\n",
    "print(\"ID for PAD:\", word2id[PAD])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf1854",
   "metadata": {},
   "source": [
    "Assertions as a partial check of your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "848d2917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "# A test which your function should pass. Note, that simply passing the test does not \n",
    "# guarantee that your function is working fully correctly.\n",
    "assert word2id[PAD] == 0\n",
    "assert len(word2id) == len(vocabulary) + 1\n",
    "print('pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa492a77",
   "metadata": {},
   "source": [
    "### Assignment 2.2\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Write a function `numericalize_ex` which takes the following arguments:\n",
    "\n",
    "1. `ex`, a string representing a review. E.g. `\"great movie !\"`\n",
    "1. `vocabulary`, the word type counter which we created above\n",
    "1. `word2id`, the mapping words -> ID numbers which we created above\n",
    "1. `min_count`, the minimum count of word type. Rarer words are filtered out.\n",
    "1. `max_count`, the maximum count of word type. More frequent words are filtered out.\n",
    "\n",
    "Your function should first split `ex` into individual tokens (you can split at spaces). You should then filter out all words whose frequency is < `min_count` or > `max_count`. \n",
    "\n",
    "Then, transform the example into a set and transform all the remaining words into ID numbers using `word2id`. Return a `torch.tensor` of shape `n`, where `n` is the count of ID numbers.\n",
    "\n",
    "When you initialize the tensor, use `dtype=torch.long`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b864a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def numericalize_ex(ex, vocabulary, word2id, min_count, max_count):\n",
    "    # 1. Split the review into tokens (split by space)\n",
    "    tokens = ex.split()\n",
    "    \n",
    "    # 2. Filter out words whose frequency is < min_count or > max_count\n",
    "    filtered_tokens = [\n",
    "        token for token in tokens\n",
    "        if min_count <= vocabulary[token] <= max_count\n",
    "    ]\n",
    "    \n",
    "    # 3. Convert the list of filtered tokens into a set (removes duplicates)\n",
    "    unique_tokens = set(filtered_tokens)\n",
    "    \n",
    "    # 4. Map each remaining word to its ID\n",
    "    # (ignore words that are not in word2id, e.g., if we had an unknown token)\n",
    "    ids = [word2id[word] for word in unique_tokens if word in word2id]\n",
    "    \n",
    "    # 5. Return a torch tensor of type long\n",
    "    return torch.tensor(ids, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a6f499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "# A test which your function should pass. Note, that simply passing the test does not \n",
    "# guarantee that your function is working fully correctly.\n",
    "assert numericalize_ex(train.text[0], vocabulary, word2id, 5, 100).size()[0] == 70\n",
    "print('pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c34742",
   "metadata": {},
   "source": [
    "### Assignment 2.3\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Write a function `numericalize()` which takes the following arguments:\n",
    "\n",
    "1. `data`, one of our datasets `train`, `dev` or `test`\n",
    "1. `data_y`, the list of numeric labels for the examples in `data` (0 or 1 corresponding to positive and negative sentiment, respectively)\n",
    "1. `vocabulary`, the word type counter which we created above\n",
    "1. `word2id`, the mapping words -> ID numbers which we created above\n",
    "1. `min_count`, the minimum count of word type. All rarer words are filtered out.\n",
    "1. `max_count`, the maximum count of word type. More frequent words get filtered out.\n",
    "1. `batch_size`, our minibatch size.\n",
    "\n",
    "You should first convert all examples in `data` into tensors using `numericalize_ex`. \n",
    "\n",
    "Then, pack the examples and their labels into minibatches containing `batch_size` examples each. Every minibatch should be a 3-tuple containing:\n",
    "\n",
    "1. A minibatch `b` of input examples of dimension `batch_size x k`, where `k` is the maximal length of an example vector in the minibatch.\n",
    "1. A minibatch of sequence lengths of shape `batch_size`, where the elements are the lengths of the examples in `b` before padding is applied.\n",
    "1. A minibatch of labels of shape `batch_size`, where each label `i` corresponds to example `b[i]`.\n",
    "\n",
    "You will need to pad all examples in `b` to the same length using the padding symbol `word2id[PAD]`. Use the pytorch function [`pad_sequence`](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html?highlight=pad_sequence) to convert a list of examples `x` of shapes `len_x` into a padded minibatch of length `batch_size x max_len_x`. You will need to call the function with the argument `batch_first=True` because we want the batch size to be the first dimension.\n",
    "\n",
    "If `batch_size` does not evenly divide `len(data)`, you may need to create one smaller minibatch to account for all training examples. This is okay.\n",
    "\n",
    "**Note:** We're returning a list from this function. It is, however, often better to create a [data loader](https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel). This can save memory when we're dealing with very large training sets. You'll learn more about this later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30b25580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def numericalize(data, data_y, vocabulary, word2id, min_count, max_count, batch_size):\n",
    "    # Convert each example into a tensor of IDs\n",
    "    numeric_examples = [\n",
    "        numericalize_ex(ex, vocabulary, word2id, min_count, max_count)\n",
    "        for ex in data.text\n",
    "    ]\n",
    "    \n",
    "    # Store all minibatches in a list\n",
    "    batches = []\n",
    "    \n",
    "    # Break the data into chunks of size 'batch_size'\n",
    "    for i in range(0, len(numeric_examples), batch_size):\n",
    "        batch_x = numeric_examples[i : i + batch_size]\n",
    "        batch_y_vals = data_y[i : i + batch_size]\n",
    "        \n",
    "        # Record the length of each sequence before padding\n",
    "        lengths = [len(x) for x in batch_x]\n",
    "        \n",
    "        # Pad all sequences in this batch to the same length\n",
    "        padded_batch_x = pad_sequence(\n",
    "            batch_x, \n",
    "            batch_first=True, \n",
    "            padding_value=word2id[PAD]\n",
    "        )\n",
    "        \n",
    "        # Convert labels for this batch into a tensor\n",
    "        batch_labels = torch.tensor(batch_y_vals, dtype=torch.long)\n",
    "        \n",
    "        # Add a 3-tuple: (padded tensor, sequence lengths, labels)\n",
    "        batches.append((\n",
    "            padded_batch_x, \n",
    "            torch.tensor(lengths, dtype=torch.long), \n",
    "            batch_labels\n",
    "        ))\n",
    "    \n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a9556c",
   "metadata": {},
   "source": [
    "Some tests to check that the number of batches which you generate looks okay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa803f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "# A test which your function should pass. Note, that simply passing the test does not \n",
    "# guarantee that your function is working fully correctly.\n",
    "batches = numericalize(train, train_y, vocabulary, word2id, 5, 100, 15)\n",
    "assert 500//15 + 1 == len(batches)\n",
    "assert batches[-1][0].size()[0] == 500 % 15\n",
    "print('pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad53fe",
   "metadata": {},
   "source": [
    "Let's then numericalize the training, development and test data using `min_count` 5, `max_count` 100 and `batch_size` 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939364bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_train = numericalize(train, train_y, vocabulary, word2id, 5, 100, 10)\n",
    "torch_dev = numericalize(dev, dev_y, vocabulary, word2id, 5, 100, 10)\n",
    "torch_test = numericalize(test, test_y, vocabulary, word2id, 5, 100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9cabf",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "\n",
    "We'll now build a CBOW model for sentiment classification.\n",
    "\n",
    "### Assignment 3.1\n",
    "rubric={accuracy:5}\n",
    "\n",
    "We'll now write a baseline torch model `CBOW` for classification of CBOW inputs. This model does not yet implement dropout or pretrained embeddings.\n",
    "\n",
    "#### The `__init__` function\n",
    "\n",
    "Your `__init__` function should take the following parameters:\n",
    "\n",
    "1. `num_words`, the number of unique word type features + 1 for the symbol `PAD` (i.e. `len(word2id)`) \n",
    "1. `num_classes`, the number of output classes . In our case, this will always be 2 because we have exactly two classes: positive and negative.\n",
    "1. `dropout_prob`, the dropout probability\n",
    "\n",
    "Your model should contain the following layers in order:\n",
    "\n",
    "1. `self.embedding`, an embedding of dimension `EMB_SIZE` which can embed all word types recognized by `word2id`\n",
    "1. `self.linear1`, a linear layer which maps `EMB_SIZE`-dimensional inputs to `HIDDEN_SIZE`-dimensional outputs\n",
    "1. `self.dropout`, dropout with probability defined by `dropout_prob`\n",
    "1. `self.relu` which applies relu to the output of `self.linear1`\n",
    "1. `self.linear2` which maps `HIDDEN_SIZE`-dimensional inputs to `num_classes`-dimensional outputs\n",
    "1. `self.log_softmax` which applies log-softmax to the output of `self.linear2`\n",
    "\n",
    "**Note**, when you initalize `self.embedding`, make sure to define `word2id[PAD]` as the padding symbol as explained [in the documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html). The effect is that `PAD` will always be embedded as the zero vector.\n",
    "\n",
    "#### The `forward` function\n",
    "\n",
    "Your forward function takes two arguments: \n",
    "\n",
    "1. a minibatch of examples `x` having shape `batch_size x k` as input.\n",
    "1. A tensor `lengths` which indiactes the length of each example in `x`. \n",
    "\n",
    "Your forward function should:\n",
    "\n",
    "1. Apply `self.embedding` to x. This results in a `batch_size x k x EMB_SIZE` tensors.\n",
    "1. You should then compute the sum of the embeddings for each example in the batch using [`torch.tensor.sum`](https://pytorch.org/docs/stable/generated/torch.sum.html?highlight=sum#torch.sum) resulting in a `batch_size x EMB_SIZE` tensor.\n",
    "1. Normalize each embedded example by dividing with the lengths in `lengths`. You can first use [`unsqueeze`](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html?highlight=unsqueeze#torch.unsqueeze) and [`expand`](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html?highlight=expand) to transform `lengths` into a `batch_size x EMB_SIZE` tensor and then use [`torch.div`](https://pytorch.org/docs/stable/generated/torch.div.html)    \n",
    "1. Pass the averaged embeddings through `self.linear1`, `self.dropout` `self.relu`, `self.linear2` and finally `self.log_softmax`. This results in a `batch_size x num_classes` tensor.\n",
    "1. Return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d838b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "HIDDEN_SIZE = 100\n",
    "EMB_SIZE = 100\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, num_words, num_classes, dropout_prob):\n",
    "        super(CBOW, self).__init__()\n",
    "        \n",
    "        # Embedding layer (with PAD=0 as padding index)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=num_words, \n",
    "            embedding_dim=EMB_SIZE, \n",
    "            padding_idx=0\n",
    "        )\n",
    "        \n",
    "        # Linear layer from EMB_SIZE to HIDDEN_SIZE\n",
    "        self.linear1 = nn.Linear(EMB_SIZE, HIDDEN_SIZE)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Final linear layer from HIDDEN_SIZE to num_classes\n",
    "        self.linear2 = nn.Linear(HIDDEN_SIZE, num_classes)\n",
    "        \n",
    "        # Log softmax for classification\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        x: batch of examples of shape (batch_size, k)\n",
    "        lengths: lengths of each example in x, shape (batch_size,)\n",
    "        \"\"\"\n",
    "        # 1. Embed input => (batch_size, k, EMB_SIZE)\n",
    "        embeddings = self.embedding(x)\n",
    "        \n",
    "        # 2. Sum across the time dimension => (batch_size, EMB_SIZE)\n",
    "        summed = embeddings.sum(dim=1)\n",
    "        \n",
    "        # 3. Normalize by lengths => (batch_size, EMB_SIZE)\n",
    "        lengths_expanded = lengths.unsqueeze(1).expand(-1, EMB_SIZE)\n",
    "        averaged = summed.div(lengths_expanded)\n",
    "        \n",
    "        # 4. Forward pass through linear, dropout, relu, linear, log_softmax\n",
    "        out = self.linear1(averaged)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.log_softmax(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29088ca",
   "metadata": {},
   "source": [
    "Assertions to check your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98520b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test which your function should pass. Note, that simply passing the test does not \n",
    "# guarantee that your function is working fully correctly.\n",
    "model = CBOW(len(word2id), 2, 0)\n",
    "model.train(False)\n",
    "x = torch_train[0]\n",
    "res = model(x[0], x[1])\n",
    "assert res.size()[0] == x[0].size()[0]\n",
    "assert res[0].exp().sum() - 1 < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7afe0",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "\n",
    "### Assignment 4.1\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Write a function `eval_model` which takes two arguments:\n",
    "\n",
    "1. `data`, a torch data set containing examples `(input_minibatch, lengths, output_minibatch)` \n",
    "1. `model` a CBOW model\n",
    "\n",
    "The function applies `model` to each input minibatch in `data` and returns the macro F-score computed by the sklearn function `f1_score`. \n",
    "\n",
    "Before running inference, make sure to call `model.train(False)` to disable dropout.\n",
    "\n",
    "**Remember** to use `with torch.no_grad()` in order to avoid computing a bunch of gradients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b69f1c",
   "metadata": {},
   "source": [
    "You can now evaluate an untrained model on the development set. The performance is unlikely to be particularly good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d71a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(len(word2id), 2, 0)\n",
    "eval_model(torch_dev, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca52376",
   "metadata": {},
   "source": [
    "### Assignment 4.2\n",
    "rubric={accuracy:3}\n",
    "\n",
    "You should now write a training function `train_model`. The function takes the following parameters:\n",
    "\n",
    "1. `model`, a CBOW model\n",
    "1. `train_data`, a dataset of torch training examples\n",
    "1. `dev_data`, a dataset of torch development examples\n",
    "1. `max_epochs`, the maximum number of epochs for training\n",
    "\n",
    "You should first:\n",
    "\n",
    "1. Initialize a `CBOW` model `model` with `len(word2id)` word types, 2 output classes and dropout probability `dropout_prob`\n",
    "1. Initialize an `Adam` optimizer for `model` (you can use the defaults for the `lr` and `betas`)\n",
    "1. Initialize an [`NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html) loss function.\n",
    "\n",
    "Run training for `max_epochs`. Each epoch iterates over the training examples `(x, lengths, y)` in `train` and:\n",
    "\n",
    "1. Calls `model.train(True)` to enable dropout\n",
    "1. Calls `zero_grad` to erase old gradients\n",
    "1. Applys the model to `x`\n",
    "1. Compute the loss w.r.t. `y`.\n",
    "1. Runs one step of backprop.\n",
    "\n",
    "You should keep track of the average loss per training example over the epoch. As a general rule, the average loss should decrease through training. \n",
    "\n",
    "Once every epoch, you need to evaluate your model on the development data. Print the average loss and the `f1_score` on the development set. \n",
    "\n",
    "Keep track of the best development accuracy and store the model which attains the best development accuracy. You can use `deepcopy` to save the model so that its parameters won't be affected by subsequent updates.\n",
    "\n",
    "Finally, return the best model you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552347e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d4146e",
   "metadata": {},
   "source": [
    "Now, train a model for `max_epochs=50` with dropout probability 30%. You will probably get within 5%-points from CountVectorizer but without pretrained embeddings, it is hard to do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93425ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(len(word2id), 2, 0.3)\n",
    "model = train_model(model, torch_train, torch_dev, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfe46d",
   "metadata": {},
   "source": [
    "Print the F-score of your model on the test data. Compare this against our CountVectorizer and TfidfVectorizer models.\n",
    "\n",
    "CBOW will probably land somewhere between CountVectorizer and TfidfVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf80e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e791e4",
   "metadata": {},
   "source": [
    "### Assignment 4.3 Optional\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Tune the hyperparameters `min_count`, `max_count` and `batch_size` (for `numericalize`) as well as `dropout_prob` (for `train_model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f4415",
   "metadata": {},
   "source": [
    "What are the best hyperparameters you found?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6240a67b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea0771",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "\n",
    "In this optional assignment, we will incorporate pretrained embeddings. You can get the embeddings [here](https://drive.google.com/file/d/1Vl5ks9DjKjSEVGtgHxL4QhxMzl2FfTem/view?usp=sharing).\n",
    "\n",
    "Let's start by reading GloVe embeddings vectors from disk. \n",
    "\n",
    "The following code block will read an embedding array `embedding` of shape `number_of_word_types x embedding_dim`. Here `embedding_dim` is `EMB_SIZE` (=100). The code will\n",
    "also read a list of all the word types `word_types` covered by the embedding. The embedding vector for `word_types[i]` is `embedding[i]`. Note that the first element `word_types[i]` is the padding symbol.\n",
    "\n",
    "This code is given to you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_types, embedding = [PAD],[[0 for i in range(EMB_SIZE)]]\n",
    "\n",
    "with open('glove.6B.100d.filtered.txt','rt') as fi:\n",
    "    full_content = fi.read().strip().split('\\n')\n",
    "\n",
    "for i in range(len(full_content)):\n",
    "    i_word = full_content[i].split(' ')[0]\n",
    "    i_emb = [float(val) for val in full_content[i].split(' ')[1:]]\n",
    "    word_types.append(i_word)\n",
    "    embedding.append(i_emb)\n",
    "    \n",
    "embedding = np.array(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520bef6",
   "metadata": {},
   "source": [
    "### Assignment 5.1 Optional\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Start by forming `pre_vocabulary` and `pre_word2id`. \n",
    "\n",
    "`pre_vocabulary` is a `Counter` which gives count 1 to all word types in `word_types`. `pre_word2id` is a dictionary which maps `word_types[i]` to its index `i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc67166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63259f98",
   "metadata": {},
   "source": [
    "Run the following cell to generate training, development and test data for a CBOW model using pretrained embeddings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_torch_train = numericalize(train, train_y, pre_vocabulary, pre_word2id, 1, 1, 10)\n",
    "pre_torch_dev = numericalize(dev, dev_y, pre_vocabulary, pre_word2id, 1, 1, 10)\n",
    "pre_torch_test = numericalize(test, test_y, pre_vocabulary, pre_word2id, 1, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e4f091",
   "metadata": {},
   "source": [
    "### Assignment 5.2 Optional\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Modify your `CBOW` code to initialize the embeddings by calling `nn.Embedding.from_pretrained()` according to [this tutorial](https://medium.com/mlearning-ai/load-pre-trained-glove-embeddings-in-torch-nn-embedding-layer-in-under-2-minutes-f5af8f57416a). Set `freeze=False`, when calling the function.\n",
    "\n",
    "You should name this new class `PreCBOW`. You don't need to touch the `forward` function. This only requires a change to `__init__`. \n",
    "\n",
    "You should pass `embedding` as an additional argument to the `__init__` function and use it when you initialize `self.embedding`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33704b2e",
   "metadata": {},
   "source": [
    "### Assignment 5.3 Optional\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Train a `PreCBOW` model on the datasets `pre_torch_train` and `pre_torch_dev` for 50 epochs with dropout probability 30%.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3545cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7d5e5",
   "metadata": {},
   "source": [
    "Now evaluate F-score on `pre_torch_test`. Your F-score should be a bit better than for CountVectorizer. Note, however, that results may change depending on random initialization. You may need to train a few times to surpass `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
